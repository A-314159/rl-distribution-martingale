------------------------------------------------------------

- Test LBFGS for graphs:
    - test toy example with powel or flip y and with hz
    - If we use step() always with a single iteration, would it simplified the code?
    - Could you write a detailed latex file that explains (the goal is for me to be able to remember precisely what was done in this chat):
        - the non-monotone armijo, (NMA)
        - the HZ,
        - the powel damping and flip y,
        - the geometric or cubic search,
        - a comparison of NMA, HZ and flip y
        - the list of gimmicks such as the ones used to handle negative curvature, division by zero, tiny curvature, non-finite issue, ...
        - a description of the minimum and correct variant for the blending with an introduction of why we may want to do that (avoid many local minima trap with a nicer function)


------------------------------
CONSIDER THIS BLENDING IDEA, BUT LATER: we need to chnage the loss function to return two gradients, or have two loss functions.

Assume we want to minimize function that is weighted average of two functions g (here g represents a function not the gradient of f) and h:
f(x) = a g(x) + (1-a) h(x).
Note that we want to have such blending when the real goal is to minimize h, but it has many local minima, while we have a function g that is easier to minimize (much less local minima) and when we guess that the optimum x for g and h are close.
Assume that we start the loop on L-BFGS step with a=1, and decrease a down to 0 over the iterations.
At iteration k, the function is f(x,k) = a(k) g(x) + (1-a(k)) h(x).
If we use L-BFGS, we run into problem because the memory contains information on the curvature of a different functions.
One way to address this is to reset the memory whenever a(k) changes, but it might not be very efficient.
Alternatively, we could keep a memory of the common s and of the changes gradients of of g and h: y_g and y_h.
Then at iteration k, we can build the new direction by building y(k-m)... y(k) from the current value a(k) and y_g(k-m)... y_g(k) and y_h(k-m)... y_h(k).
What do think about it? Is it worth the effort? Do you see any other idea?

-----------------------------



    - Test HZ
    - Test in FP64
    - Review precision setups for ML configuration and BFGS
    (we can run the model in FP32 but compute the loss in FP64,
    therefore, BFGS should inspect the precision of the loss function rather than the type of the variable)
    - Test on ML=FP32, Loss=FP64, Opt=FP64
    - Test on ML=FP32, Loss=FP32, Opt=FP64
    - Test on ML=FP32, Loss=FP32, Opt=FP32

- Distribution
    - test on hint distribution:
        - eager mode first
        - graph mode to check if it works
    - test on bellman equation (that might still not work since the new code)
    (KEEP IN MIND THAT BLENDING MIGHT CAUSE BFGS TO FAIL)
    - launch a long training and check is distribution = MC distrib

- ES and actor:
    - implement and test (various mode of actor)

- Review my paper
Request to chat gpt about the paper:
I will rewrite a bit the better later. The concept is that my work is more generic that for just the example of hedging in finance.
What I think is new in the approach includes:
a) The usage of very small discretization for the evaluation of expectation in bellman equation. Generically possible if there is a model for the universe (empirical or theoretical) for short time evolution because the error is proportion to the time step. This avoids freezing gradients as in some other RL approaches. (I never saw such an approach)
b) A simple representation of the distribution, without the need to ensure monotonicity. (I read some papers that imposed monotonicity via complicated things)
Do you think that the above items are indeed new? Do you think they can be useful for other RL problems, outside or in the field of finance?
Can you find references of articles for comparison?

------------------------------------------------------------

- GPU:
    - try fixing the GPU one more time: https://www.crazywebstudio.co.th/blog/how-to-solve-code-43-nvidia-gtx10xx-or-rtx20xx-gpu-problem/)
    - test speed (graph) and convergence (impact of different operation results)
    - refactor the train method into a tf_function (otherwise perf loss 10x-100x)

- Integrate and test the bandit adaptive version of lbfgs

- review my prior work on martingale
    - think about how to make a more generic implementation:
        - problems: bergomi vanilla, BS with div, American digit, callable bond
        - harmonize use/concept of continuation value
        - implement (harmonized + bandit ready)
    - Ask for help / advice from ChatGPT on how to do the above (directly reading my paper)

- Test gnlm (but param need to be fine-tune, very slow as is). If it works, do a version for graphs
- Try the agent mode of chat gpt (later)
- Try the cloud computing
- Build a word document to summarize what I did to create the repo, commit, push, how to use github, use the agent, use cloud computing via github
